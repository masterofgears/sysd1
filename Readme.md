# Простой пример разработки System Design для ETL системы

## Первоначальная постановка задачи (выдержка из ТЗ)
**Функционал и описание**

Продукт обеспечивает доступ пользователей Заказчиков к исходным данным, которые генерируются в процессе работы «ХХХ”. 

Доступ к данным осуществляется через абстрактное представление – «Витрина данных» (или по тексту далее – витрина).

Данные реплицируется в витрину из основной СУБД «ХХХ”, согласно заданным правилам.

Пользователи витрины: программист  DevExpress,  программист SQL, специалист по BI-аналитики.

**Цель продукта**
* обеспечить доступ Заказчика к данным «ХХХ”, для разработки кастомных отчётов силами Заказчика.
* оградить Заказчика от доступа к секретным данным СУБД «ХХХ” (полям и таблицам), которые представляют коммерческую тайну.
* исключить негативное влияние Заказчика на СУБД «ХХХ” и работоспособность «ХХХ” в целом, которое Заказчик может оказать в результате неконтролируемого прямого доступа к СУБД «ХХХ”.

**Требования к архитектуре ПО**

* При разработке архитектуры необходимо локализовать ПО в виде микросервиса для «ХХХ”.
* Планируется, что продукт будет работать на серверном оборудовании совместно с ПО «ХХХ”, либо на отдельном сервере (виртуальном или физическом), выделенным для витрины данных. Доступ Заказчика к витрине данных будет производится, в форме подключения к стандартной реляционной базе данных. Извлечение данных при помощи языка запросов SQL. 

Предлагается разделить витрину данных на две части:

* Первая «оперативная» часть – исходные данные в прямом виде, как и в СУБД «ХХХ”, для работы с оперативной информацией для простых запросов (которые используют малые объёмы данных ли имеют простую логику), планируемая глубина архива 3 месяцев до 1 года.
* Вторая «аналитическая» часть – преобразованные данные для работы с большим объёмом  данных (большое число записей, большой период выборки, сложные запросы с одновременным выводом множества значений). Предполагается, что данная часть витрины будет представлять из себя технологию OLAP (куб или столбцовая система управления базами данных или другое). Также данная часть будет использована для BI-аналитики в разрезе нескольких лет. Планируемая глубина архива 3 года.

Необходимо определить механизм повторной загрузки данных из СУБД «ХХХ” в витрину, при изменении данных в СУБД «ХХХ”. Но если, мы не сможем решить проблему с автоматической загрузкой измененных данных в витрину, то потребуется frontend для заказчика, для ручной миграции данных из СУБД «ХХХ” в витрину данных.

Разделение витрины данных на две части обусловлено технологическими ограничениями OLTP классического способа организации базы данных. 

Все технологии, используемые в продукте, должны быть на основе открытой лицензии.

На этапе технической проработки продукта необходимо понять все ограничения, которые будут наложены на конечный продукт, в зависимости от выбранной технологии.

*(**Важно: спроектировать дизайн без уточняющих требований, AS IS**)*


# System Design
## Первоначальный анализ системы “Витрина Данных”

*Глоссарий:*
- **БД Истоник** - база данных Заказчика из которой происходит репликация данных. На текущий момент это базы: Oracle, MSSQL, PostgreSQL
- **БД Приемник** - целевая БД, куда будут реплицироваться данные. На текущий момент это PostgreSQL
- **CDC-механизм** - Change Data Capture, механизм, обеспечивающий получение данных в изменяющихся таблицах

Предложенная нотация C4


### Системный контекст
Состоит из:
* Сама система XXX
* Витрина данных 
* Пользователи системы XXX

![](https://github.com/masterofgears/sysd1/blob/main/xxx-syscontent.png)

---

### Компонентная  диаграмма

Состоит из:
* Система ХХХ
* Механизм репликации данных
* WEB-интерфейс управления Витриной Данных
* БД Витрины данных
* Микросервисы, обеспечивающих работу
* Пользователей системы

![](https://github.com/masterofgears/sysd1/blob/main/xxx-component.png)

---

## LLD (Контейнеры)

### Репликатор данных

В качестве реплицирующего механизма был выбран Debezium

Состоит из:
* Debezium с коннекторами по умолчанию
* PostgreSQL JDBC Kafka Connector
* Oracle JDBC Kafka Connector
* MSSQL JDBC Kafka Connector

![](https://github.com/masterofgears/sysd1/blob/main/sys-xxx-repl-container.png)

Схема работы:

Debezium подлючается к репликам БД Источника и начинает принимать изменения или производить первоначальную загрузку данных

Полученны данные, согласно выбранной схеме из микросервсиа "Управление схемами БД", продюсируются в Kafka Connect посредством соответствующих JDBC коннекторов по правилу: один топик - одна таблица

---

### Управление схемами БД

Микросервис, обеспечивающий корректную работу репликации. Для этого необходимо получать схемы из БД Источника (таблицы, поля)

Это связано с тем, что:
- Не все таблицы и поля необходимо реплицировать из БД Источника в БД Применик
- Ограничения накладываемые PostgreSQL JDBC Kafka Connector
- При репликации, необходимо приводить типы данных из БД Источника в типы данных БД Приемника. Например, гео-данные

Состоит из:
* SQL Mapper
* Scheme Table
* Scheme Creator 
* Настройки для конкретных БД

![](https://github.com/masterofgears/sysd1/blob/main/sys-xxx-schememanage-container.png)

Схема работы:

Микросервис соединяется с БД Источника и запрашивает схему данных

Сравнивает полученную схему с той, которая необходима для репликации (получает ее из WEB-приложения)

Преобразует типы данных (поля) в те, которые поддерживает БД Приемник (PostgreSQL)

Создает в БД Приемник схему и таблицы, согласно преобразованным типам и схеме полученной из WEB-интерфейса

---

### CDC-механизм

Микросервис, обеспечивающий конфигурирование коннектора Debezium для конкретной БД Источника

Состоит из:
* Connector Manager
* Debezium Handler
* Настройки для конкретных БД и параметры топиков Kafka

![](https://github.com/masterofgears/sysd1/blob/main/sys-xxx-cdc-container.png)

Схема работы:

Микросервис из WEB-интерфейса получает схему данных, которую необходимо реплицировать

На основании схемы, формирует коннектор Debezium с БД Источника (ограничения, таблицы, поля, заморозка данных)


---

### Схема управления CDC-механизмом

Показан механизм, как происходит взаимодействие CDC-механизма с различными типами БД 

![](https://github.com/masterofgears/sysd1/blob/main/sys-xxx-msa-container.png)

Схема работы:

Микросервисы соединяется с БД Источника и запрашивает схему данных, формируют таблицы в БД Приемник

На основе схемы для БД Приемника, формируется конфигурационный файл для Debezium


---

### Управление задачами

Элемент Витрины Данных, обеспечивающий работу по трансформации данных и обработки таблиц.

Задача представляет собой набор инструкций для Airflow или DBT в зависисмости от типа реплцируемых данных и логики

Состоит из:
* DBT Task Manager
* Airflow Task Handler

![](https://github.com/masterofgears/sysd1/blob/main/sys-xxx-taskmanage-container.png)

Схема работы:

Задачи, необходимые для работы загружаются в 2 независимых контура
- Airflow - OLTP обработка данных, обеспечивающее прямую репликацию или репликацию с обработкой исходных данных
- DBT - OLAP механизм, позволяющий производить формирование "витрин данных" для конечного потребителя

---


### Основаная последовательность работы

![](https://github.com/masterofgears/sysd1/blob/main/xxx-main-seq.png)

---

### Схема данных

![](https://github.com/masterofgears/sysd1/blob/main/sys-xxx-db.png)


### Обоснование

**Используемое ПО**
* Apache Kafka - транспорт для CDC и некое временное хранилище для архива записей с глубиной от 3 мес до 3 лет
* Debezium - CDC инструмент
* Source- и sink- Kafka Connector - обеспечивает взаимодействие Kafka и БД
* Apache Airflow -  механизм, по расписанию выполнять те или иные задачи
* DBT - механизм, позволяющий формирование отчености
* Python - неплохой язык, плюс “дружит” с Airflow
* HA-Proxy - балансировщик запросов от пользователей, по-факту интерфейс доступа

**Обеспечение стабильности**

Используется подход Change Data Capture - OutBox, который позволяет инкрементально “забирать” изменения в БД ХХХ, далее продюсировать их в топик Kafka, где Apache Airflow или DBT производят ETL процесс.

А именно:

* обфускация данных, для предотвращения попадания в Витрину секретных данных (таблицы с обработкой)
* трансформация данных для предопределенных запросов BI
* Формирования вьюх (при необходимости)

**Обоснование:**

* в случае выхода  из строя или профилактической работы “Хранилища для витрины данных” все изменения сохраняются в Реплицирующем механизме. Далее, по восстановлении работы, данные передаются в Хранилище
* в случае  выхода из строя или проф. работа реплицирующиеся механизма, “Витрина данных” продолжает работу как независимый элемент. Далее, по восстановлении работы, данные передаются в Хранилище

Восстановление данных происходит из топиков Kafka по последнему сохраненному offset в служебном топике


**Ограничения**

* необходим коннектор к конкретным БД для Debezium
* необходим коннектор Airflow для конкретных БД
* вероятно будет нужна библиотека Python для трансформации стандартного SQL в формат Аналитической БД, в случае прямого запроса к аналитической БД, трансформация не нужна
* выбор языка Python обусловлен использованием ПО в конкретной реализации


