# Простой пример  Архитектурного решения для ETL системы

## Первоначальная постановка задачи (выдержка из ТЗ)
**Функционал и описание**

Продукт обеспечивает доступ пользователей Заказчиков к исходным данным, которые генерируются в процессе работы «ХХХ”. 

Доступ к данным осуществляется через абстрактное представление – «Витрина данных» (или по тексту далее – витрина).

Данные реплицируется в витрину из основной СУБД «ХХХ”, согласно заданным правилам.

Пользователи витрины: программист  DevExpress,  программист SQL, специалист по BI-аналитики.

**Цель продукта**
* обеспечить доступ Заказчика к данным «ХХХ”, для разработки кастомных отчётов силами Заказчика.
* оградить Заказчика от доступа к секретным данным СУБД «ХХХ” (полям и таблицам), которые представляют коммерческую тайну.
* исключить негативное влияние Заказчика на СУБД «ХХХ” и работоспособность «ХХХ” в целом, которое Заказчик может оказать в результате неконтролируемого прямого доступа к СУБД «ХХХ”.

**Требования к архитектуре ПО**

* При разработке архитектуры необходимо локализовать ПО в виде микросервиса для «ХХХ”.
* Планируется, что продукт будет работать на серверном оборудовании совместно с ПО «ХХХ”, либо на отдельном сервере (виртуальном или физическом), выделенным для витрины данных. Доступ Заказчика к витрине данных будет производится, в форме подключения к стандартной реляционной базе данных. Извлечение данных при помощи языка запросов SQL. 

*Предлагается разделить витрину данных на две части:*

* Первая «оперативная» часть – исходные данные в прямом виде, как и в СУБД «ХХХ”, для работы с оперативной информацией для простых запросов (которые используют малые объёмы данных ли имеют простую логику), планируемая глубина архива 3 месяцев до 1 года.
* Вторая «аналитическая» часть – преобразованные данные для работы с большим объёмом  данных (большое число записей, большой период выборки, сложные запросы с одновременным выводом множества значений). Предполагается, что данная часть витрины будет представлять из себя технологию OLAP (куб или столбцовая система управления базами данных или другое). Также данная часть будет использована для BI-аналитики в разрезе нескольких лет. Планируемая глубина архива 3 года.

Необходимо определить механизм повторной загрузки данных из СУБД «ХХХ” в витрину, при изменении данных в СУБД «ХХХ”. Но если, мы не сможем решить проблему с автоматической загрузкой измененных данных в витрину, то потребуется frontend для заказчика, для ручной миграции данных из СУБД «ХХХ” в витрину данных.

Разделение витрины данных на две части обусловлено технологическими ограничениями OLTP классического способа организации базы данных. 

Все технологии, используемые в продукте, должны быть на основе открытой лицензии.

На этапе технической проработки продукта необходимо понять все ограничения, которые будут наложены на конечный продукт, в зависимости от выбранной технологии.

*(**Важно: спроектировать дизайн без уточняющих требований, AS IS**)*



# Architecture Design
### Глоссарий (краткий)
- **Истоник** - база(ы) данных Заказчика из которой происходит репликация данных. На текущий момент это базы: Oracle, MSSQL, PostgreSQL
- **Приемник** - целевая БД, куда будут реплицироваться данные. На текущий момент это PostgreSQL
- **Apache Kafka** - транспорт для CDC и некое временное хранилище для архива записей с глубиной от 3 мес до 3 лет
* **Debezium** - CDC инструмент
* **Source- и sink- Kafka Connector** - обеспечивает взаимодействие Kafka и БД
* **Apache Airflow** -  механизм, по расписанию выполнять те или иные задачи
* **DBT** - механизм, позволяющий формирование отчености
* **Python** - неплохой язык, плюс “дружит” с Airflow



### Заинтересованные лица (Stakeholders)
* **Администратор**: представитель Заказчика, который осуществляет управление репликациями из Источника. Управление происходит через web-интерфейс
* **Разработчик**: программист, пищущие Python-скрипты под управлением Apache Airflow.
* **SQL-разработчик**: программист, пишущий процедуры для доступа к данным в PostgreSQL и скрипты для DBT
* **Аналитик**: потребитель системы, строящий отчеты и/или финализирует обработку данных, для предачи во внешние подсистемы



### Функциональные требования

№  | Функциональное требование
----- | -----
FT-1 | Необходимо репликцировать исторические данные  из  Источник разной глубины (в днях) 
FT-2 | Система должна очищать чуствительные данные из Источника
FT-3 | Для репликации данных, необходимо  иметь возможность выбора схемы, таблиц, столбцов из Источника
FT-4 | Необходимо объединять, трансформировать данные из разных Источников, перед помещение в Приемник
FT-5 | Система должна иметь возможность обогащения данных из Источника, перед помещением в приемник

### Нефункциональные требования

№  | Тип |Нефункциональное требование
----- | ------ | ------
NFT-1 | Доступность | Высокая доступность системы с максимальным количеством незапланированных простоев **15 минут в день**, что соответствует **99%** SLA
NFT-2 | Производительность | Время работы интефейса должно быть ограничено 800 мс.
NFT-3 | Производительность | Репликация и очистка данных  из Источника(ов) в Приемник должна быть произведена в течение **2 минут** с момента их создания Источником.
NFT-4 | Производительность | Обогащение данных из Источника(ов) в Приемник должна быть произведена в течение **3 минут** с момента их создания Источником.
NFT-5 | Производительность | Транфсформация данных должна быть произведена из Источника(ов) в Приемник в течение **5 минут** с момента их создания Источником.
NFT-6 | Масштабируемость | Обслуживание не менее **3 БД Источника** и при увеличении количества БД Источника автоматически масштабировать.
NFT-7 | Расширяемость | Внесение функциональный изменений не должно сказываться на производительности системы

## Предполагаемая архитектура системы “Витрина Данных”

## Context Viewpoint
### Level 1 - Системный контекст
В системе точки интеграции:
* **Витрина**: сама система, которая занимается обработкой реплицируемых данных
* **Система XXX**: внешний ПАК, который гененрирует данные (Источник). В тривиальном случае, это просто БД или более сложно-организованное ПО, которое может сохранять данные в БД
* **Пользователи системы XXX**:  заинтересованные лица, участвующие в эксплуатации **Витрины**



![](https://github.com/masterofgears/sysd1/blob/main/c4/sysd-context.png)

---

### Level 2 - Компонентная  диаграмма

* **Система ХХХ**
* **Механизм репликации данных**: основная идея использования **СDC** (Change Data Capture), механизм, обеспечивающий получение данных в изменяющихся таблицах.
* **WEB-интерфейс управления Витриной Данных**: интерфейс для Администратора, в котором он выбирает БД для репликации, таблицы и столбцы, которые доллжны будут перенесены из Источника в Приемник
* **БД Витрины данных**: целевая БД, в которую реплицируются данные из Источника. Представляет собой логически разделенную одну физическую БД на 2 логические
* **Пользователей системы**

![](https://github.com/masterofgears/sysd1/blob/main/c4/sysd-component.png)

---

## Level 3 - Контейнеры

### Level 3 - Контейнер - Репликатор данных
Реализует ADR 02


Debezium подлючается к репликам БД Источника и начинает принимать изменения или производить первоначальную загрузку данных. В каком формате работать, выставляет Администратор в Web-интерфейсе Витрины Данных.

Полученны данные, согласно выбранной схеме из микросервсиа "Управление схемами БД", продюсируются в Kafka Connect посредством соответствующих JDBC коннекторов по правилу: один топик - одна таблица.


Состоит из:
* **Debezium**
* **PostgreSQL JDBC Kafka Connector**
* **Oracle JDBC Kafka Connector**
* **MSSQL JDBC Kafka Connector**

Диаграмма взаимодействия

![](https://github.com/masterofgears/sysd1/blob/main/c4/seq-repl-container.png)

Схема контейнера

![](https://github.com/masterofgears/sysd1/blob/main/c4/sysd-repl-container.png)



---

### Level 3 - Контейнеры - Управление схемами БД
Реализует ADR 04

Микросервис, обеспечивающий корректную работу репликации.

**Администратор**, задает таблицы и поля для реплицирования. Создается новая схема в БД Приемника, согласно выбору из БД Источника

Для этого  получать схемы из БД Источника (таблицы, поля). Далее, схема сохраняется в локальном хранилище и создается правило, в котором указаны, какие поля и таблицы из схемы Источника необходимо реплицировать.

*Это связано с тем, что:*
- Не все таблицы и поля необходимо реплицировать из БД Источника в БД Применик
- Ограничения накладываемые PostgreSQL JDBC Kafka Connect Driver
- При репликации, необходимо приводить типы данных из БД Источника в типы данных БД Приемника. Например, гео-данные или json-данные

Состоит из:
* **SQL Mapper** - преобразует типы данных БД Источника в БД Приемник
* **Scheme Table** - запрашивает через прямой SQL-запрос схему БД Источника
* **Scheme Creator** - сохраняет конкретные схемы и БД Приемника. Это необходимо, чтобы Kafka Connect корректно принял структуру таблиц Приемника
* **Настройки для конкретных БД Источника** - учетные записиси, хосты, настройки подключения и т.д.


![](https://github.com/masterofgears/sysd1/blob/main/c4/sysd-schememanage-container.png)

**Схема работы**

Микросервис соединяется с БД Источника и запрашивает схему данных

Сравнивает полученную схему с той, которая необходима для репликации (получает ее из WEB-приложения)

Преобразует типы данных (поля) в те, которые поддерживает БД Приемник (PostgreSQL)

Создает в БД Приемник схему и таблицы, согласно преобразованным типам и схеме полученной из WEB-интерфейса

**Диаграмма взаимодействия**

![](https://github.com/masterofgears/sysd1/blob/main/c4/seq-schememanage.png)

---

### CDC-механизм

Микросервис, обеспечивающий конфигурирование коннектора Debezium для конкретной БД Источника

Состоит из:
* **Connector Manager**: реализация API Debezium и API Kafka Connect для мониторинга и управления коннекторами 
* **Debezium Handler**: формирование и управление конфигурационным файлом для подлючения к конкретной БД Источника
* **Настройки для конкретных БД и параметры топиков Kafka**: настройки для соединений


**Схема работы**

Микросервис из WEB-интерфейса получает схему данных, которую необходимо реплицировать

На основании схемы, формирует коннектор Debezium с БД Источника (ограничения, таблицы, поля, заморозка данных)


![](https://github.com/masterofgears/sysd1/blob/main/c4/sysd-cdc-container.png)

---

### Схема управления CDC-механизмом

Показан механизм, как происходит взаимодействие CDC-механизма с различными типами БД 

Схема работы:

Микросервисы соединяется с БД Источника и запрашивает схему данных, формируют таблицы в БД Приемник

На основе схемы для БД Приемника, формируется конфигурационный файл для Debezium


![](https://github.com/masterofgears/sysd1/blob/main/c4/sysd-msa-container.png)




---

### Управление задачами

Элемент Витрины Данных, обеспечивающий работу по трансформации данных и обработки таблиц.

Задача представляет собой набор инструкций для Airflow или DBT в зависисмости от типа реплцируемых данных и логики

Состоит из:
* DBT Task Manager
* Airflow Task Handler

![](https://github.com/masterofgears/sysd1/blob/main/c4/sysd-taskmanage-container.png)

Схема работы:

Задачи, необходимые для работы загружаются в 2 независимых контура
- **Airflow**:  OLTP обработка данных, обеспечивающее прямую репликацию или репликацию с обработкой исходных данных
- **DBT**: OLAP механизм, позволяющий производить формирование "витрин данных" для конечного потребителя

---


### Основаная последовательность работы

![](https://github.com/masterofgears/sysd1/blob/main/xxx-main-seq.png)

---

### Схема данных

![](https://github.com/masterofgears/sysd1/blob/main/c4/sys-xxx-db.png)


### ADR

ADR 01: Apache Airflow
ADR 02: Debezium
ADR 03: Kafka
ADR 04: Запрос схемы БД из Источника

## Обоснование архитектурного решения
**Обеспечение стабильности**

Используется подход Change Data Capture - он позволяет инкрементально “забирать” изменения в БД ХХХ, далее продюсировать их в топик Kafka, где Apache Airflow или DBT производят ETL процесс.

А именно:

* обфускация данных, для предотвращения попадания в Витрину секретных данных (таблицы с обработкой)
* трансформация данных для предопределенных запросов BI
* Формирования вьюх (при необходимости)

**Обоснование**

* в случае выхода  из строя или профилактической работы “Хранилища для витрины данных” все изменения сохраняются в Реплицирующем механизме. Далее, по восстановлении работы, данные передаются в Хранилище

* в случае  выхода из строя или проф. работа реплицирующиеся механизма, “Витрина данных” продолжает работу как независимый элемент. Далее, по восстановлении работы, данные передаются в Хранилище

* Восстановление данных происходит из топиков Kafka по последнему сохраненному offset в служебном топике


## Ограничения

* необходим коннектор к конкретным БД для Debezium
* необходим коннектор Airflow для конкретных БД
* вероятно будет нужна библиотека Python для трансформации стандартного SQL в формат Аналитической БД, в случае прямого запроса к аналитической БД, трансформация не нужна
* выбор языка Python обусловлен использованием ПО в конкретной реализации


